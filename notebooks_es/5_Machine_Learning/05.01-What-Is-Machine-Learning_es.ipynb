{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué es el aprendizaje automático?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Antes de echar un vistazo a los detalles de varios métodos de aprendizaje automático, comencemos por ver qué es y qué no es el aprendizaje automático.\n",
    "El aprendizaje automático a menudo se clasifica como un subcampo de la inteligencia artificial, pero encuentro que la categorización puede ser engañosa.\n",
    "El estudio del aprendizaje automático ciertamente surgió de la investigación en este contexto, pero en la aplicación de métodos de aprendizaje automático a la ciencia de datos, es más útil pensar en el aprendizaje automático como un medio para *construir modelos de datos*.\n",
    "\n",
    "En este contexto, el \"aprendizaje\" entra en juego cuando damos a estos modelos *parámetros ajustables* que pueden adaptarse a los datos observados; de esta manera se puede considerar que el programa está \"aprendiendo\" de los datos.\n",
    "Una vez que estos modelos se han ajustado a los datos vistos anteriormente, se pueden utilizar para predecir y comprender aspectos de los datos recién observados.\n",
    "Dejaré al lector la digresión más filosófica sobre hasta qué punto este tipo de \"aprendizaje\" matemático basado en modelos es similar al \"aprendizaje\" exhibido por el cerebro humano.\n",
    "\n",
    "Comprender la configuración de problemas en el aprendizaje automático es esencial para utilizar estas herramientas de manera efectiva, por lo que comenzaremos con algunas categorizaciones amplias de los tipos de enfoques que discutiremos aquí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Categorías de aprendizaje automático\n",
    "\n",
    "El aprendizaje automático se puede clasificar en dos tipos principales: aprendizaje supervisado y aprendizaje no supervisado.\n",
    "\n",
    "El *aprendizaje supervisado* implica de alguna manera modelar la relación entre las características medidas de los datos y algunas etiquetas asociadas con los datos; Una vez que se determina este modelo, se puede utilizar para aplicar etiquetas a datos nuevos y desconocidos.\n",
    "A veces, esto se subdivide en tareas de clasificación y tareas de regresión: en *clasificación*, las etiquetas son categorías discretas, mientras que en *regresión*, las etiquetas son cantidades continuas.\n",
    "Verá ejemplos de ambos tipos de aprendizaje supervisado en la siguiente sección.\n",
    "\n",
    "El *aprendizaje no supervisado* implica modelar las características de un conjunto de datos sin referencia a ninguna etiqueta.\n",
    "Estos modelos incluyen tareas como *agrupación* y *reducción de dimensionalidad.*\n",
    "Los algoritmos de agrupamiento identifican distintos grupos de datos, mientras que los algoritmos de reducción de dimensionalidad buscan representaciones más concisas de los datos.\n",
    "También verá ejemplos de ambos tipos de aprendizaje no supervisado en la siguiente sección.\n",
    "\n",
    "Además, existen los llamados métodos de *aprendizaje semi-supervisado*, que se encuentran en algún punto entre el aprendizaje supervisado y el aprendizaje no supervisado.\n",
    "Los métodos de aprendizaje semisupervisados ​​suelen ser útiles cuando sólo se dispone de etiquetas incompletas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ejemplos cualitativos de aplicaciones de aprendizaje automático\n",
    "\n",
    "Para concretar estas ideas, echemos un vistazo a algunos ejemplos muy simples de una tarea de aprendizaje automático.\n",
    "Estos ejemplos están destinados a brindar una descripción general intuitiva y no cuantitativa de los tipos de tareas de aprendizaje automático que veremos en esta parte del libro.\n",
    "En capítulos posteriores, profundizaremos en los modelos particulares y cómo se utilizan.\n",
    "Para obtener una vista previa de estos aspectos más técnicos, puede encontrar la fuente de Python que genera las siguientes figuras en el [apéndice] en línea (https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/06.00-Figure-Code .ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Clasificación: predicción de etiquetas discretas\n",
    "\n",
    "Primero veremos una tarea de clasificación simple, en la que se nos proporciona un conjunto de puntos etiquetados y queremos usarlos para clasificar algunos puntos sin etiquetar.\n",
    "\n",
    "Imaginemos que tenemos los datos que se muestran en esta figura:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![](imagenes/05.01-clasificacion-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Estos datos son bidimensionales: es decir, tenemos dos *características* para cada punto, representadas por las posiciones (x,y) de los puntos en el plano.\n",
    "Además, tenemos una de dos *etiquetas de clase* para cada punto, aquí representadas por los colores de los puntos.\n",
    "A partir de estas características y etiquetas, nos gustaría crear un modelo que nos permita decidir si un nuevo punto debe etiquetarse como \"azul\" o \"rojo\".\n",
    "\n",
    "Hay varios modelos posibles para tal tarea de clasificación, pero comenzaremos con uno muy simple. Supondremos que los dos grupos se pueden separar trazando una línea recta que pase por el plano entre ellos, de manera que los puntos a cada lado de la línea caigan todos en el mismo grupo.\n",
    "Aquí el *modelo* es una versión cuantitativa de la afirmación \"una línea recta separa las clases\", mientras que los *parámetros del modelo* son los números particulares que describen la ubicación y orientación de esa línea para nuestros datos.\n",
    "Los valores óptimos para estos parámetros del modelo se aprenden a partir de los datos (este es el \"aprendizaje\" en el aprendizaje automático), lo que a menudo se denomina *entrenamiento del modelo*.\n",
    "\n",
    "Consulte la siguiente figura que muestra una representación visual de cómo se ve el modelo entrenado para estos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![](imagenes/05.01-clasificacion-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ahora que este modelo ha sido entrenado, se puede generalizar a datos nuevos sin etiquetar.\n",
    "En otras palabras, podemos tomar un nuevo conjunto de datos, trazar esta línea a través de él y asignar etiquetas a los nuevos puntos según este modelo (consulte la siguiente figura).\n",
    "Esta etapa generalmente se llama *predicción*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![](imagenes/05.01-clasificacion-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Esta es la idea básica de una tarea de clasificación en el aprendizaje automático, donde \"clasificación\" indica que los datos tienen etiquetas de clase discretas.\n",
    "A primera vista esto puede parecer trivial: es fácil mirar nuestros datos y trazar una línea discriminatoria para lograr esta clasificación.\n",
    "Sin embargo, una ventaja del enfoque de aprendizaje automático es que puede generalizarse a conjuntos de datos mucho más grandes en muchas más dimensiones.\n",
    "\n",
    "Por ejemplo, esto es similar a la tarea de detección automática de spam en el correo electrónico. En este caso, podríamos utilizar las siguientes características y etiquetas:\n",
    "\n",
    "- *característica 1*, *característica 2*, etc. $\\to$ recuentos normalizados de palabras o frases importantes (\"Viagra\", \"Garantía extendida\", etc.)\n",
    "- *etiqueta* $\\to$ \"spam\" o \"no spam\"\n",
    "\n",
    "Para el conjunto de capacitación, estas etiquetas podrían determinarse mediante inspección individual de una pequeña muestra representativa de correos electrónicos; para los correos electrónicos restantes, la etiqueta se determinaría utilizando el modelo.\n",
    "Para un algoritmo de clasificación adecuadamente entrenado con suficientes características bien construidas (normalmente miles o millones de palabras o frases), este tipo de enfoque puede resultar muy eficaz.\n",
    "Veremos un ejemplo de dicha clasificación basada en texto en [En profundidad: clasificación ingenua de Bayes] (05.05-Naive-Bayes.ipynb).\n",
    "\n",
    "Algunos algoritmos de clasificación importantes que analizaremos con más detalle son el Bayes ingenuo gaussiano (consulte [En profundidad: Clasificación Naive Bayes] (05.05-Naive-Bayes.ipynb)), las máquinas de vectores de soporte (consulte [En profundidad: Máquinas de vectores de soporte] (05.07-Support-Vector-Machines.ipynb)) y clasificación de bosques aleatorios (consulte [En profundidad: árboles de decisión y bosques aleatorios](05.08-Random-Forests.ipynb))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Regresión: predicción de etiquetas continuas\n",
    "\n",
    "En contraste con las etiquetas discretas de un algoritmo de clasificación, a continuación veremos una tarea de regresión simple en la que las etiquetas son cantidades continuas.\n",
    "\n",
    "Considere los datos que se muestran en la siguiente figura, que consta de un conjunto de puntos, cada uno con una etiqueta continua."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![](imagenes/05.01-regresión-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Al igual que en el ejemplo de clasificación, tenemos datos bidimensionales: es decir, hay dos características que describen cada punto de datos.\n",
    "El color de cada punto representa la etiqueta continua de ese punto.\n",
    "\n",
    "Hay varios modelos de regresión posibles que podríamos usar para este tipo de datos, pero aquí usaremos un modelo de regresión lineal simple para predecir los puntos.\n",
    "Este modelo simple supone que si tratamos la etiqueta como una tercera dimensión espacial, podemos ajustar un plano a los datos.\n",
    "Ésta es una generalización de nivel superior del conocido problema de ajustar una línea a datos con dos coordenadas.\n",
    "\n",
    "Podemos visualizar esta configuración como se muestra en la siguiente figura:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![](imagenes/05.01-regresión-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Observe que el plano *característica 1–característica 2* aquí es el mismo que en el gráfico bidimensional de la Figura 37-4; en este caso, sin embargo, hemos representado las etiquetas tanto por color como por posición de eje tridimensional.\n",
    "Desde este punto de vista, parece razonable que ajustar un plano a través de estos datos tridimensionales nos permita predecir la etiqueta esperada para cualquier conjunto de parámetros de entrada.\n",
    "Volviendo a la proyección bidimensional, cuando ajustamos dicho plano obtenemos el resultado que se muestra en la siguiente figura:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![](imagenes/05.01-regresión-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Este plano de ajuste nos brinda lo que necesitamos para predecir etiquetas para nuevos puntos.\n",
    "Visualmente nos encontramos con los resultados que se muestran en la siguiente figura:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![](imagenes/05.01-regression-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Como ocurre con el ejemplo de clasificación, esta tarea puede parecer trivial en un número reducido de dimensiones.\n",
    "Pero el poder de estos métodos es que pueden aplicarse y evaluarse directamente en el caso de datos con muchas, muchas características.\n",
    "\n",
    "Por ejemplo, esto es similar a la tarea de calcular la distancia a las galaxias observadas a través de un telescopio; en este caso, podríamos usar las siguientes características y etiquetas:\n",
    "\n",
    "- *característica 1*, *característica 2*, etc. $\\to$ brillo de cada galaxia en una de varias longitudes de onda o colores\n",
    "- *etiqueta* $\\to$ distancia o corrimiento al rojo de la galaxia\n",
    "\n",
    "Las distancias de un pequeño número de estas galaxias podrían determinarse mediante un conjunto independiente de observaciones (normalmente más costosas o complejas).\n",
    "Las distancias a las galaxias restantes podrían entonces estimarse utilizando un modelo de regresión adecuado, sin necesidad de emplear la observación más costosa en todo el conjunto.\n",
    "En los círculos de astronomía, esto se conoce como el problema del \"desplazamiento al rojo fotométrico\".\n",
    "\n",
    "Algunos algoritmos de regresión importantes que discutiremos son la regresión lineal (ver [En profundidad: Regresión lineal](05.06-Linear-Regression.ipynb)), máquinas de vectores de soporte (ver [En profundidad: Máquinas de vectores de soporte](05.07-Support- Vector-Machines.ipynb)) y regresión de bosque aleatorio (consulte [En profundidad: árboles de decisión y bosques aleatorios] (05.08-Random-Forests.ipynb))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Agrupación: inferir etiquetas en datos sin etiquetar\n",
    "\n",
    "Las ilustraciones de clasificación y regresión que acabamos de ver son ejemplos de algoritmos de aprendizaje supervisado, en los que intentamos construir un modelo que prediga etiquetas para nuevos datos.\n",
    "El aprendizaje no supervisado implica modelos que describen datos sin hacer referencia a ninguna etiqueta conocida.\n",
    "\n",
    "Un caso común de aprendizaje no supervisado es el \"agrupamiento\", en el que los datos se asignan automáticamente a una cierta cantidad de grupos discretos.\n",
    "Por ejemplo, podríamos tener algunos datos bidimensionales como los que se muestran en la siguiente figura:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![](imagenes/05.01-clustering-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A simple vista, queda claro que cada uno de estos puntos forma parte de un grupo distinto.\n",
    "Dada esta información, un modelo de agrupación utilizará la estructura intrínseca de los datos para determinar qué puntos están relacionados.\n",
    "Usando el muy rápido e intuitivo algoritmo *k*-means (ver [En profundidad: K-Means Clustering](05.11-K-Means.ipynb)), encontramos los clusters que se muestran en la siguiente figura:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![](imagenes/05.01-clustering-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*k*-means se ajusta a un modelo que consta de *k* centros de conglomerados; Se supone que los centros óptimos son aquellos que minimizan la distancia de cada punto a su centro asignado.\n",
    "Una vez más, esto podría parecer un ejercicio trivial en dos dimensiones, pero a medida que nuestros datos se vuelven más grandes y complejos, estos algoritmos de agrupamiento pueden seguir utilizándose para extraer información útil del conjunto de datos.\n",
    "\n",
    "Analizaremos el algoritmo *k*-means con más profundidad en [En profundidad: agrupación de K-Means](05.11-K-Means.ipynb).\n",
    "Otros algoritmos de agrupamiento importantes incluyen modelos de mezcla gaussiana (consulte [En profundidad: modelos de mezcla gaussiana] (05.12-Gaussian-Mixtures.ipynb)) y agrupamiento espectral (consulte [documentación de agrupamiento de Scikit-Learn] (http://scikit-learn.org /stable/modules/clustering.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Reducción de dimensionalidad: inferir la estructura de datos sin etiquetar\n",
    "\n",
    "La reducción de dimensionalidad es otro ejemplo de algoritmo no supervisado, en el que las etiquetas u otra información se infieren de la estructura del propio conjunto de datos.\n",
    "La reducción de dimensionalidad es un poco más abstracta que los ejemplos que vimos antes, pero generalmente busca extraer alguna representación de datos de baja dimensión que de alguna manera preserve las cualidades relevantes del conjunto de datos completo.\n",
    "Diferentes rutinas de reducción de dimensionalidad miden estas cualidades relevantes de diferentes maneras, como veremos en [En profundidad: Aprendizaje múltiple] (05.10-Manifold-Learning.ipynb).\n",
    "\n",
    "Como ejemplo de esto, considere los datos que se muestran en la siguiente figura:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![](imagenes/05.01-dimesionalidad-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Visualmente, está claro que hay cierta estructura en estos datos: están dibujados a partir de una línea unidimensional que se dispone en espiral dentro de este espacio bidimensional.\n",
    "En cierto sentido, se podría decir que estos datos son \"intrínsecamente\" sólo unidimensionales, aunque estos datos unidimensionales están incrustados en un espacio bidimensional.\n",
    "Un modelo de reducción de dimensionalidad adecuado en este caso sería sensible a esta estructura incrustada no lineal y podría detectar esta representación de menor dimensionalidad.\n",
    "\n",
    "La siguiente figura muestra una visualización de los resultados del algoritmo Isomap, un algoritmo de aprendizaje múltiple que hace exactamente esto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![](imagenes/05.01-dimesionalidad-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Observe que los colores (que representan la variable latente unidimensional extraída) cambian uniformemente a lo largo de la espiral, lo que indica que el algoritmo de hecho detectó la estructura que vimos a simple vista.\n",
    "Al igual que con los ejemplos anteriores, el poder de los algoritmos de reducción de dimensionalidad se vuelve más claro en casos de dimensiones superiores.\n",
    "Por ejemplo, es posible que deseemos visualizar relaciones importantes dentro de un conjunto de datos que tiene 100 o 1000 características.\n",
    "Visualizar datos de 1000 dimensiones es un desafío, y una forma de hacerlo más manejable es utilizar una técnica de reducción de dimensionalidad para reducir los datos a 2 o 3 dimensiones.\n",
    "\n",
    "Algunos algoritmos de reducción de dimensionalidad importantes que discutiremos son el análisis de componentes principales (ver [En profundidad: Análisis de componentes principales] (05.09-Principal-Component-Analysis.ipynb)) y varios algoritmos de aprendizaje múltiples, incluido Isomap e incrustación lineal local (ver [ En profundidad: aprendizaje múltiple] (05.10-Manifold-Learning.ipynb))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Resumen\n",
    "\n",
    "Aquí hemos visto algunos ejemplos simples de algunos de los tipos básicos de enfoques de aprendizaje automático.\n",
    "No hace falta decir que hay una serie de detalles prácticos importantes que hemos pasado por alto, pero este capítulo fue diseñado para darle una idea básica de qué tipos de problemas pueden resolver los enfoques de aprendizaje automático.\n",
    "\n",
    "En resumen, vimos lo siguiente:\n",
    "\n",
    "- *Aprendizaje supervisado*: Modelos que pueden predecir etiquetas basadas en datos de entrenamiento etiquetados\n",
    "\n",
    "  - *Clasificación*: Modelos que predicen etiquetas como dos o más categorías discretas\n",
    "  - *Regresión*: Modelos que predicen etiquetas continuas\n",
    "  \n",
    "- *Aprendizaje no supervisado*: Modelos que identifican la estructura en datos sin etiquetar\n",
    "\n",
    "  - *Clustering*: Modelos que detectan e identifican distintos grupos en los datos.\n",
    "  - *Reducción de dimensionalidad*: Modelos que detectan e identifican estructuras de dimensiones inferiores en datos de dimensiones superiores\n",
    "  \n",
    "En las siguientes secciones profundizaremos mucho más en estas categorías y veremos algunos ejemplos más interesantes de dónde estos conceptos pueden resultar útiles.\n",
    "\n",
    "Todas las cifras de la discusión anterior se generan en base a cálculos reales de aprendizaje automático; el código detrás de ellos se puede encontrar en el [Apéndice: Código de figura](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/06.00-Figure-Code.ipynb)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
